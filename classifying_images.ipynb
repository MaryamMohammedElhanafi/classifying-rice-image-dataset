{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "l48xqvEXL6Sb",
        "outputId": "de6c9e26-82bf-403c-9c2f-b1bef6236ce1"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVfFkDoK_3wr"
      },
      "outputs": [],
      "source": [
        " ! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpMf0kjw_5JI"
      },
      "outputs": [],
      "source": [
        "'''import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle''''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "zv9ufW8ur-Cb",
        "outputId": "f6c9ffd7-67ee-433f-b459-5988103c9f8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-347eab2e-d08b-4ce6-bf6f-ac36487152d7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-347eab2e-d08b-4ce6-bf6f-ac36487152d7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"marmoh\",\"key\":\"7ef6c3cd0b867678fcb9271d320218dd\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3guGlht__TJ"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvFkN1kBsPMm"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3v5DrqNsdKE",
        "outputId": "ee6e5ff3-a1e0-4774-9825-280e2cb005a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ref                                                             title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "rohit265/credit-card-eligibility-data-determining-factors       Credit Card Eligibility Data: Determining Factors  296KB  2024-05-18 11:31:28           1103         24  1.0              \n",
            "rahulvyasm/netflix-movies-and-tv-shows                          Netflix Movies and TV Shows                          1MB  2024-04-10 09:48:38          25843        551  1.0              \n",
            "mayankanand2701/netflix-stock-price-dataset                     Netflix Stock Price Dataset 🎥🍿🎬📊                   107KB  2024-05-25 06:59:35            708         32  1.0              \n",
            "prasad22/vehicle-population-statistics                          Vehicle Population Statistics                       44KB  2024-05-25 03:31:34            842         28  1.0              \n",
            "bhargavlc/studentsperformance                                   StudentsPerformance                                  3KB  2024-05-28 09:44:50           1151         25  1.0              \n",
            "prasad22/weather-data                                           Weather Data                                        43MB  2024-05-18 14:27:35           1876         46  1.0              \n",
            "jainaru/thyroid-disease-data                                    Thyroid Disease Data                                 3KB  2024-05-10 12:06:31           3642         85  1.0              \n",
            "jainaru/dog-breeds-ranking-best-to-worst                        Dog breeds ranked 🐕🐾                                 4KB  2024-05-18 13:28:47            822         34  1.0              \n",
            "emirhanai/social-media-usage-and-emotional-well-being           Social Media Usage and Emotional Well-Being          8KB  2024-05-19 18:25:52           2238         43  1.0              \n",
            "zeesolver/spotfy                                                Spotify Songs Album                                 47KB  2024-05-10 09:21:57           2247         33  1.0              \n",
            "sahirmaharajj/school-student-daily-attendance                   School Student Daily Attendance                      2MB  2024-04-29 19:29:56           7313        148  1.0              \n",
            "vladimirmijatovic/biggest-companies-in-the-world                Biggest Companies in the World                     189KB  2024-05-16 13:39:09            666         29  1.0              \n",
            "amanbarthwal/imdb-movies-data                                   IMDB Movies Dataset                                  8MB  2024-05-16 18:43:48           2040         36  1.0              \n",
            "girumwondemagegn/dataset-for-renewable-energy-systems           Dataset for renewable energy systems               853KB  2024-05-17 23:51:25           1279         32  1.0              \n",
            "kanchana1990/perfume-e-commerce-dataset-2024                    Perfume E-Commerce Dataset 2024                    106KB  2024-05-24 18:53:32            728         30  1.0              \n",
            "sahilnbajaj/marketing-campaigns-data-set                        Marketing Campaigns Data Set                        61KB  2024-05-04 04:19:58            976         23  1.0              \n",
            "shreyanshverma27/online-sales-dataset-popular-marketplace-data  Online Sales Dataset - Popular Marketplace Data      7KB  2024-05-25 23:55:26            828         22  1.0              \n",
            "mayankanand2701/zomato-stock-price-dataset                      Zomato Stock Price Dataset 📊🍗🏨🍴                     13KB  2024-05-23 06:42:34           1044         27  1.0              \n",
            "jainaru/world-happiness-report-2024-yearly-updated              World Happiness Report- 2024                        62KB  2024-05-15 19:04:34           2885         47  1.0              \n",
            "jainaru/electric-vehicle-population                             Electric Vehicle Data                                6MB  2024-05-21 18:40:16           1197         33  1.0              \n"
          ]
        }
      ],
      "source": [
        " ! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCspYdsGsib1",
        "outputId": "35649a1c-d77b-4dde-cf36-19f40dc3cf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading rice-image-dataset.zip to /content\n",
            " 98% 214M/219M [00:02<00:00, 119MB/s]\n",
            "100% 219M/219M [00:02<00:00, 101MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d muratkokludataset/rice-image-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30I5d6JKtgcs"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Define the path to your zip file\n",
        "file_path = '/content/rice-image-dataset.zip'\n",
        "\n",
        "# Unzip the file to a specific destination\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/kaggle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCGwHRLjvLeT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.applications.mobilenet_v2 import decode_predictions\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUNmlDOGHdhF",
        "outputId": "d0142f60-f21f-469a-9b79-4f33634c9efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pip install split-folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg4PHddfOZOB"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSCiX2snNb7-",
        "outputId": "46a54620-b802-481c-dfab-11452bdfc1f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 75000 files [00:14, 5150.01 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "input_folder = \"/content/kaggle/Rice_Image_Dataset\"\n",
        "output = \"/content/testt\"\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output, seed=42, ratio=(.8, .2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rF85Hq9vPbg",
        "outputId": "614c9970-f266-419a-fc1c-499ececd680c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/testt/train\n"
          ]
        }
      ],
      "source": [
        "base_dir_path = os.getcwd()\n",
        "print(base_dir_path)\n",
        "train_dir_path = os.path.join(base_dir_path,'testt/train')\n",
        "print(train_dir_path)\n",
        "test_dir_path = os.path.join(base_dir_path,'testt/val')\n",
        "MNet_InputSize = (224,224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlYr8KLYvqfd"
      },
      "outputs": [],
      "source": [
        "def getAllClassNames(dir_path):\n",
        "    return os.listdir(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm2i8ZRJvwqP"
      },
      "outputs": [],
      "source": [
        "def understandData(BASE_DIR_PATH,train_or_test):\n",
        "    \"\"\"\n",
        "    Function prints number of images per class in train/test directory\n",
        "    <CLASS-NAME    NUMBER-OF-IMAGES>\n",
        "\n",
        "    Args:\n",
        "        BASE_DIR_PATH(str): path of the base directory\n",
        "        train_or_test(str): directory to select train/test\n",
        "    \"\"\"\n",
        "    train_dir_path = os.path.join(BASE_DIR_PATH,train_or_test)\n",
        "    test_dir_path = os.path.join(BASE_DIR_PATH,'testt/val')\n",
        "    print(\"Number of Classes = \",len(os.listdir(train_dir_path)))\n",
        "    AllClassNames = os.listdir(train_dir_path)\n",
        "    print(\"Class Names = \",AllClassNames)\n",
        "    print('CLASS NAME'+'\\t'+'NUMBER OF IMAGES')\n",
        "    for class_name in AllClassNames:\n",
        "        print(class_name+'\\t',len(os.listdir(os.path.join(train_dir_path,class_name))))\n",
        "    displaySampleImages(train_dir_path,AllClassNames)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdF4SVNhv2Mc"
      },
      "outputs": [],
      "source": [
        "def displaySampleImages(PATH_TO_DIR,ALL_CLASS_NAMES):\n",
        "    \"\"\"\n",
        "    Display grid of sample images for every class in dataset.\n",
        "\n",
        "    Args:\n",
        "        PATH_TO_DIR(str): path to train or test dir.\n",
        "        ALL_CLASS_NAMES(str): list of all class names.\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib as mpl\n",
        "    mpl.rcParams['axes.titlesize'] = 8\n",
        "    import glob\n",
        "    import cv2\n",
        "    #NoOfClasses = len(ALL_CLASS_NAMES)\n",
        "    fig = plt.figure()\n",
        "    fig.subplots_adjust(hspace=0.7, wspace=0.1)\n",
        "    fig.suptitle('Understanding Fruit-360 Dataset', fontsize=16)\n",
        "    for n,class_name in enumerate(ALL_CLASS_NAMES):\n",
        "        ImagePath = glob.glob(os.path.join(PATH_TO_DIR,class_name)+'/*.jpg')[0]\n",
        "        #print(ImagePath)\n",
        "        Img = cv2.imread(ImagePath)\n",
        "        ax = fig.add_subplot(10,10,(n+1))\n",
        "        plt.imshow(cv2.cvtColor(Img, cv2.COLOR_BGR2RGB))\n",
        "        ax.set_title(class_name+str(n))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U3_2F2Vv2nt"
      },
      "outputs": [],
      "source": [
        "def readData(BASE_DIR_PATH):\n",
        "    \"\"\"\n",
        "    Console output of,\n",
        "        total number of classes in train/test dir\n",
        "        total number of images in train/test dir\n",
        "    in given dataset.\n",
        "\n",
        "    Args:\n",
        "        BASE_DIR_PATH(str): path to root dir\n",
        "    \"\"\"\n",
        "    nb_of_train_files = 0\n",
        "    nb_of_test_files = 0\n",
        "\n",
        "    train_dir_path = os.path.join(BASE_DIR_PATH,'testt/train')\n",
        "    test_dir_path = os.path.join(BASE_DIR_PATH,'testt/val')\n",
        "    AllClassNames_train = os.listdir(train_dir_path)\n",
        "    AllClassNames_test = os.listdir(test_dir_path)\n",
        "    print('Number of Classes in train DataSet: ',len(AllClassNames_train))\n",
        "    print('Number of Classes in test DataSet: ',len(AllClassNames_test))\n",
        "    for class_name in AllClassNames:\n",
        "        nb_of_train_files = nb_of_train_files + len(os.listdir(os.path.join(train_dir_path,class_name)))\n",
        "        nb_of_test_files = nb_of_test_files + len(os.listdir(os.path.join(test_dir_path,class_name)))\n",
        "    print('Number of train samples: ',nb_of_train_files)\n",
        "    print('Number of test samples:',nb_of_test_files)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeOJPZ-Nv21o"
      },
      "outputs": [],
      "source": [
        "def id_class_name(class_id, classes):\n",
        "    \"\"\"\n",
        "    Returns name of the class as per the given id\n",
        "\n",
        "    Args:\n",
        "        class_id(int): Number of the class.\n",
        "        classes(dict): dictinary of all the classes in given dataset.\n",
        "\n",
        "    returns:\n",
        "        Name of the Class.\n",
        "    \"\"\"\n",
        "    for key, value in classes.items():\n",
        "        if class_id == key:\n",
        "            return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HWQZEKEwL-6"
      },
      "outputs": [],
      "source": [
        "def predictRiceClass(ImagePath,trainedModel,DictOfClasses):\n",
        "    \"\"\"\n",
        "    Perform class prediction on input image and print predicted class.\n",
        "\n",
        "    Args:\n",
        "        ImagePath(str): Absolute Path to test image\n",
        "        trainedModel(object): trained model from method getTrainedModel()\n",
        "        DictOfClasses(dict): python dict of all image classes.\n",
        "\n",
        "    Returns:\n",
        "        Probability of predictions for each class.\n",
        "\n",
        "    \"\"\"\n",
        "    x = image.load_img(ImagePath, target_size=MNet_InputSize)\n",
        "    x = image.img_to_array(x)\n",
        "    #for Display Only\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow((x * 255).astype(np.uint8))\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    prediction_class = trainedModel.predict_classes(x,batch_size=1)\n",
        "    prediction_probs = trainedModel.predict_proba(x,batch_size=1)\n",
        "    #print(prediction_probs)\n",
        "    class_value = id_class_name(prediction_class,DictOfClasses)\n",
        "    print(class_value)\n",
        "    return prediction_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj2IOPlzwL0c"
      },
      "outputs": [],
      "source": [
        "def getTrainedModel(PATH_TO_TRAINED_MODEL_FILE):\n",
        "    \"\"\"\n",
        "    Loads trained-saved model from file(.h5) and returns as a object.\n",
        "\n",
        "    Args:\n",
        "        PATH_TO_TRAINED_MODEL_FILE(str): path to saved model file.\n",
        "\n",
        "    returns:\n",
        "        trainedModel(model object): returns a model saved as a <.h5>\n",
        "    \"\"\"\n",
        "    from tensorflow.keras.models import load_model\n",
        "    traiendModel = load_model(PATH_TO_TRAINED_MODEL_FILE)\n",
        "    return traiendModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeuvYEudwLqA"
      },
      "outputs": [],
      "source": [
        "def plotResults(historyObject):\n",
        "    \"\"\"\n",
        "    Summary:\n",
        "        Plots train-validation loss and accuracy graphs for given history object\n",
        "\n",
        "    Args:\n",
        "        historyObject(object): Object returned by fit/fit_generator during train.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNbPsA4AwqTP"
      },
      "outputs": [],
      "source": [
        "AllClassNames = getAllClassNames(train_dir_path)\n",
        "num_of_classes = len(AllClassNames)\n",
        "DictOfClasses = {i : AllClassNames[i] for i in range(0, len(AllClassNames))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXFr8QTwwqI8",
        "outputId": "6c719d8b-a376-4c15-cd38-c0dc625e62b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 1280)              2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               655872    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2916421 (11.13 MB)\n",
            "Trainable params: 658437 (2.51 MB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base = MobileNetV2(weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        pooling='avg')\n",
        "conv_base.trainable = False\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_of_classes,activation='softmax'))\n",
        "\n",
        "optimizer = Adam(lr=1e-5)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrztjnGvwqAi"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                             shear_range=0.4,\n",
        "                             zoom_range=0.2,\n",
        "                             rotation_range=50,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLl_NIr4wp4d",
        "outputId": "a9178861-3126-4ff3-d783-6bed5223499a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 60000 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 48\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_dir_path,  # this is the target directory\n",
        "        target_size=MNet_InputSize,  # all images will be resized\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyUTQ-FZwpxU",
        "outputId": "17a42277-8b1e-40f9-a373-d589f4a030bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15000 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        test_dir_path,  # this is the target directory\n",
        "        target_size=MNet_InputSize,  # all images will be resized\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rtqYmXzxPww",
        "outputId": "d29cdece-398c-448a-9085-ba69e30b3798"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-b0c24f04d516>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 544/1250 [============>.................] - ETA: 29:11 - loss: 0.1380 - accuracy: 0.9499"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                          epochs=1,\n",
        "                          validation_data = test_generator,\n",
        "                          verbose=1)\n",
        "\n",
        "model.save('rice_image_trained.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTEfQGIjxXzk"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    base_dir_path = os.getcwd()\n",
        "    train_dir_path = os.path.join(base_dir_path,'train')\n",
        "    test_dir_path = os.path.join(base_dir_path,'test')\n",
        "    MNet_InputSize = (224,224)\n",
        "\n",
        "    understandData(base_dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UR-EYNAxXrK"
      },
      "outputs": [],
      "source": [
        "#    ImagePath = 'test/Banana Red/99_100.jpg'\n",
        "#    path_trained_model = \"E:/Py_Proj/ML/EXPLORES/deep_object_detect/fruits-360/trained_model/fruit_360_trained_16JUL.h5\"\n",
        "#    trainedModel = getTrainedModel(path_trained_model)\n",
        "#    AllProbs = predictFruitClass(ImagePath,trainedModel,DictOfClasses)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}